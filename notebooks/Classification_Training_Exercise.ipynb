{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Training Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification training pipeline using plain pytorch and a custom model\n",
    "- as classification of all 4 classes turns out to be rather difficult, we will focus on classifying negative or positive for pneumonia only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:32.308250Z",
     "iopub.status.busy": "2021-05-21T11:21:32.307893Z",
     "iopub.status.idle": "2021-05-21T11:21:33.631675Z",
     "shell.execute_reply": "2021-05-21T11:21:33.630819Z",
     "shell.execute_reply.started": "2021-05-21T11:21:32.308211Z"
    }
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Albumenatations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# importing from local package\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from src.visualization.images import show_img\n",
    "from src.visualization.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:33.692018Z",
     "iopub.status.busy": "2021-05-21T11:21:33.691583Z",
     "iopub.status.idle": "2021-05-21T11:21:33.702230Z",
     "shell.execute_reply": "2021-05-21T11:21:33.701424Z",
     "shell.execute_reply.started": "2021-05-21T11:21:33.691982Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\" seed random number generators to make runs deterministic \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "\n",
    "# TODO: try training with different values for \n",
    "# - learning rate\n",
    "# - batch size\n",
    "# - image size\n",
    "# - number of epochs\n",
    "# - fold number\n",
    "    \n",
    "class Config:\n",
    "    \"\"\" Configuration for the training \"\"\"\n",
    "    \n",
    "    lr: float = 1e-3 # learning rate\n",
    "    batch_size: int = 4 # size of training batches\n",
    "    img_size: int = (256, 256) # image size for model input\n",
    "    n_epochs: int = 100           \n",
    "    fold_num: int = 0 # chooses fold for training. Available folds: [0, 1, 2]\n",
    "    \n",
    "    time_stamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S') # current time (for logging)\n",
    "    exp_name = f\"classification_{time_stamp}\" \n",
    "    log_path = Path(\"./logs\") / exp_name # name of the log folder                  \n",
    "    seed: int = 2021 # for random number generators        \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # computing device    \n",
    "    num_workers: int = 4 # number of processors used to prepare the batches. Adjust to number of CPUs on your machine     \n",
    "    num_classes: int = 2 # number of classes\n",
    "    label_dict = {\n",
    "        0 : \"negative\",\n",
    "        1 : \"positive\"\n",
    "    }    \n",
    "\n",
    "seed_everything(Config.seed) # makes the results reproducible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_batch(images, gt_labels, image_ids, pred_labels=None):\n",
    "    \"\"\" plots image batch returned from dataloader and optionally predictions\n",
    "    \n",
    "    Expects data to be detached from gradients and moved to CPU\n",
    "    \"\"\"\n",
    "    \n",
    "    # for visibility, plot only a few images for large batches\n",
    "    n_plot_max = 8\n",
    "    if len(images) > n_plot_max:\n",
    "        n_plot = n_plot_max        \n",
    "        sample_idx = torch.randperm(len(images))[:n_plot]        \n",
    "        images = images[sample_idx]        \n",
    "        gt_labels = gt_labels[sample_idx]                \n",
    "        image_ids = [image_ids[i.item()] for i in sample_idx]\n",
    "        if pred_labels is not None:\n",
    "            pred_labels = pred_labels[sample_idx]\n",
    "    else:\n",
    "        n_plot = len(images)\n",
    "    \n",
    "    n_cols=2\n",
    "    n_rows=n_plot // 2    \n",
    "    \n",
    "    figsize= (n_cols * 7, n_rows * 7)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 14),  nrows=n_rows, ncols=n_cols)\n",
    "    for n in range (n_plot):    \n",
    "        img_id = image_ids[n]\n",
    "        gt_label = gt_labels[n].item()\n",
    "        img = images[n].numpy()\n",
    "        img = np.squeeze(img)\n",
    "\n",
    "        row = n // n_cols\n",
    "        col = n % n_cols \n",
    "        ax[row][col].imshow(img, cmap='gray')   \n",
    "        ax[row][col].axis('off')    \n",
    "        \n",
    "        if pred_labels is None:\n",
    "            title = f\"{image_id}: {Config.label_dict[gt_label]}\"\n",
    "        else:\n",
    "            pred_label = pred_labels[n].item()\n",
    "            title = f\"{image_id}: GT {Config.label_dict[gt_label]}, Pred {Config.label_dict[pred_label]}\"\n",
    "        \n",
    "        ax[row][col].set_title(title)    \n",
    "\n",
    "    plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data/siim-covid19-detection-subset')\n",
    "train_path = data_path / \"train\"\n",
    "\n",
    "# annotation data frame\n",
    "ann_df = pd.read_csv(data_path / \"train_annotations.csv\", converters={\n",
    "    \"boxes\": literal_eval, \n",
    "    \"labels\": literal_eval,\n",
    "    \"pixel_spacing\": literal_eval\n",
    "   })  \n",
    "\n",
    "ann_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Pre-Processing\n",
    "\n",
    "Image processing serves two purposes:\n",
    "\n",
    "- it standardizes the images shown to the model\n",
    "- it augments the data with with new images by applying random transformations to the existing images\n",
    "- to guarantee that the images are still standardized, the standardization is applied after the augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:33.733067Z",
     "iopub.status.busy": "2021-05-21T11:21:33.732798Z",
     "iopub.status.idle": "2021-05-21T11:21:33.740040Z",
     "shell.execute_reply": "2021-05-21T11:21:33.738984Z",
     "shell.execute_reply.started": "2021-05-21T11:21:33.733038Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalization transforms\n",
    "norm_transform_list = [\n",
    "    A.Resize(height=Config.img_size[0], width=Config.img_size[1], p=1.0),\n",
    "    A.Normalize(mean=(0,), std=(1,), p=1.0),\n",
    "    ToTensorV2(p=1.0)    \n",
    "]\n",
    "\n",
    "aug_transform_list = [\n",
    "    # TODO: add augmentation transforms\n",
    "    # Think about wich ones are reasonable for the data set\n",
    "    # Check whether they do what intended in the data sanity checks\n",
    "    # Observe their influence on the training process\n",
    "]\n",
    "\n",
    "train_transforms = A.Compose(aug_transform_list + norm_transform_list)\n",
    "val_transforms = A.Compose(norm_transform_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader\n",
    "\n",
    "- see [DATASETS & DATALOADERS](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) for an explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, data_path, transforms=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        sample = self.df.iloc[index]\n",
    "\n",
    "        img_path = self.data_path / sample['rel_image_path']\n",
    "        image_id = sample[\"id\"]\n",
    "        label = sample[\"study_label\"]\n",
    "\n",
    "        # TODO implement the remaining logic\n",
    "        raise NotImplementedError(\"Replace this error with the actual implementation\")\n",
    "        # Hint: for the start we try to only classify positive and negative cases\n",
    "        # you can use `label = int(label > 0)` for this purpose\n",
    "\n",
    "        return img, label, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a common practice to split the data into several folds for training. This data was split into 3 folds.<br>\n",
    "The idea is that you use the selected fold for validation only and the remaining folds for training. This way you can check during the training whether your model performance generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:33.758802Z",
     "iopub.status.busy": "2021-05-21T11:21:33.758432Z",
     "iopub.status.idle": "2021-05-21T11:21:33.773130Z",
     "shell.execute_reply": "2021-05-21T11:21:33.772324Z",
     "shell.execute_reply.started": "2021-05-21T11:21:33.758766Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = ann_df[ann_df['fold'] != Config.fold_num]\n",
    "val_df = ann_df[ann_df['fold'] == Config.fold_num]\n",
    "\n",
    "train_ds = ClassificationDataset(train_df, train_path, train_transforms)\n",
    "val_ds = ClassificationDataset(val_df, train_path, val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: When using batch size > 1, one should shuffle the data for training. Otherwise the model might learn to deduce the label based on the sequence of the data shown. This will of course break the system during real inference. <br>\n",
    "For the validation the sequence doesn't matter. So to avoid additional processing, one can skip the shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:33.758802Z",
     "iopub.status.busy": "2021-05-21T11:21:33.758432Z",
     "iopub.status.idle": "2021-05-21T11:21:33.773130Z",
     "shell.execute_reply": "2021-05-21T11:21:33.772324Z",
     "shell.execute_reply.started": "2021-05-21T11:21:33.758766Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size = Config.batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = Config.num_workers\n",
    "    )\n",
    "val_dl = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size = Config.batch_size,\n",
    "        shuffle = False,\n",
    "        num_workers = Config.num_workers        \n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Sanity Check\n",
    "\n",
    "To find errors in the data loading and augmentation implementation, it is a good practice to visualize a few images before showing them to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:33.774773Z",
     "iopub.status.busy": "2021-05-21T11:21:33.774430Z",
     "iopub.status.idle": "2021-05-21T11:21:33.948894Z",
     "shell.execute_reply": "2021-05-21T11:21:33.948049Z",
     "shell.execute_reply.started": "2021-05-21T11:21:33.774739Z"
    }
   },
   "outputs": [],
   "source": [
    "image, label, image_id = train_ds[2]\n",
    "\n",
    "img_np = image.numpy()\n",
    "img_np = np.squeeze(img_np)\n",
    "gt_label = label.item()\n",
    "    \n",
    "_ = show_img(img_np, figsize=(12, 12), title=f\"{image_id}: {Config.label_dict[gt_label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:33.959547Z",
     "iopub.status.busy": "2021-05-21T11:21:33.958937Z",
     "iopub.status.idle": "2021-05-21T11:21:38.481005Z",
     "shell.execute_reply": "2021-05-21T11:21:38.480021Z",
     "shell.execute_reply.started": "2021-05-21T11:21:33.959507Z"
    }
   },
   "outputs": [],
   "source": [
    "images, labels, image_ids = next(train_it)\n",
    "\n",
    "plot_image_batch(images, labels, image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "See [BUILD THE NEURAL NETWORK](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
    "\n",
    "[TORCHVISION.MODELS](https://pytorch.org/vision/stable/models.html#torchvision-models) contains a list of models which can be used for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationBaseline(nn.Module):\n",
    "    \"\"\" This is a simple baseline model, based on the Resnet architecture\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "        # input for grayscale images\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=(\n",
    "            7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "        # adjust number of output classes\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, cfg.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO develop your own model based on the tutorial\n",
    "# Note: if you run on a CPU, it is better to use small models (few layers with few features)\n",
    "# See how the custom model performs compared to the baseline\n",
    "\n",
    "class ClassificationCustom(nn.Module):\n",
    "    def __init__(self, cfg) -> None:\n",
    "        super().__init__()\n",
    "        # TODO add your network layers here\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        # TODO add inference logic here        \n",
    "        raise NotImplementedError(\"Replace this error message after implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:38.592357Z",
     "iopub.status.busy": "2021-05-21T11:21:38.592040Z",
     "iopub.status.idle": "2021-05-21T11:21:39.369772Z",
     "shell.execute_reply": "2021-05-21T11:21:39.368876Z",
     "shell.execute_reply.started": "2021-05-21T11:21:38.592319Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(cfg, checkpoint_path=None):\n",
    "    \n",
    "    model = ClassificationBaseline(cfg)    \n",
    "    #model = ClassificationCustom(cfg)    \n",
    "    \n",
    "    # Load the trained weights\n",
    "    if checkpoint_path is not None:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        del checkpoint\n",
    "        gc.collect()\n",
    "        \n",
    "    return model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(Config)\n",
    "model.to(Config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: develop the classification training logic\n",
    "\n",
    "class ClassificationTrainer():\n",
    "    def __init__(self, model, cfg) -> None:\n",
    "        self.cfg = cfg\n",
    "        self.model = model\n",
    "        # TODO: all variables you need for the implementation are added here\n",
    "\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        writer = SummaryWriter(self.log_base)\n",
    "        for e in range(self.cfg.n_epochs):\n",
    "            \n",
    "            # TODO (optional) add more logic to the overall training procedure. E.g.:\n",
    "            # better logging\n",
    "            # save best model only\n",
    "            # any learning rate schedule\n",
    "            # anything else you find or want to try out\n",
    "            \n",
    "            train_loss, train_acc = self.train_epoch(train_loader)            \n",
    "            print(f'Train. Epoch: {e}, train_loss: {train_loss:.5f}, train_accuracy: {train_acc:.5f}')\n",
    "\n",
    "            val_loss, val_acc = self.validate_epoch(validation_loader)\n",
    "            print(f'Val. Epoch: {e}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')                        \n",
    "\n",
    "    def train_epoch(self, train_loader):\n",
    "        \n",
    "        # TODO implement training logic\n",
    "        # it should compute the training loss\n",
    "        # score is optional, but usefull to compare with the validation score\n",
    "        # for this data set accuracy is a useful metric\n",
    "        raise NotImplementedError(\"Replace this error message after implementation\")\n",
    "\n",
    "        return loss, score\n",
    "\n",
    "    def validate_epoch(self, val_loader):\n",
    "        \n",
    "        # TODO implement validation logic\n",
    "        # it should compute the validation loss and score (e.g. accuracy)        \n",
    "        raise NotImplementedError(\"Replace this error message after implementation\")\n",
    "\n",
    "        return epoch_loss.avg, score.acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:38.592357Z",
     "iopub.status.busy": "2021-05-21T11:21:38.592040Z",
     "iopub.status.idle": "2021-05-21T11:21:39.369772Z",
     "shell.execute_reply": "2021-05-21T11:21:39.368876Z",
     "shell.execute_reply.started": "2021-05-21T11:21:38.592319Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = ClassificationTrainer(model, Config)\n",
    "trainer.fit(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "This is to inspect whether the model learned something reasonable. <br>\n",
    "Typically the type of errors a model makes gives hints on what should be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:40.190243Z",
     "iopub.status.busy": "2021-05-21T11:21:40.189964Z",
     "iopub.status.idle": "2021-05-21T11:21:41.276719Z",
     "shell.execute_reply": "2021-05-21T11:21:41.275880Z",
     "shell.execute_reply.started": "2021-05-21T11:21:40.190212Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = Config.log_path / 'path/to/trained/model/file'\n",
    "\n",
    "model = get_model(Config, checkpoint_path=model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterators allow to loop through the data step-by-step<br>\n",
    "Every time `next` is called on the iterator it fetches new samples from the data set <br>\n",
    "So simply re-run the inference cell to see some results <br>\n",
    "Every time the iterator definition cell is executed, the iterator will start from the beginning again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_it = iter(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:39.417113Z",
     "iopub.status.busy": "2021-05-21T11:21:39.416817Z",
     "iopub.status.idle": "2021-05-21T11:21:40.185922Z",
     "shell.execute_reply": "2021-05-21T11:21:40.184909Z",
     "shell.execute_reply.started": "2021-05-21T11:21:39.417088Z"
    }
   },
   "outputs": [],
   "source": [
    "images, gt_labels, image_ids = next(val_it)\n",
    "images = images.to(Config.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(images)\n",
    "    \n",
    "images = images.cpu()\n",
    "_, preds = torch.max(logits, 1)\n",
    "\n",
    "pred_labels = preds.cpu()\n",
    "\n",
    "plot_image_batch(images, gt_labels, image_ids, pred_labels=pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Score\n",
    "\n",
    "Loop through the whole dataset to compute the validation scores <br>\n",
    "Here the 'confusion matrix' is used. See [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) <br>\n",
    "It can be used to calculate the accuracy but gives more insights on the type of errors which occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# understand the confusion matrix\n",
    "# understand its connection to true positives, false positives, true negatives and false negatives\n",
    "# understand how to calculate 'precision' and 'recall' from it (or if you prefer 'sensitivity' and 'specificity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gt_labels = torch.zeros(len(val_ds), dtype=torch.long, device='cpu')\n",
    "all_pred_labels = torch.zeros(len(val_ds), dtype=torch.long, device='cpu')\n",
    "\n",
    "for i, (images, gt_labels, image_ids) in enumerate(val_dl):\n",
    "    n_samples = len(image_ids)\n",
    "    \n",
    "    images = images.to(Config.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(images)\n",
    "    \n",
    "    _, preds = torch.max(logits, 1)\n",
    "\n",
    "    pred_labels = preds.cpu()\n",
    "    \n",
    "    all_gt_labels[i*n_samples:(i+1)*n_samples] = gt_labels\n",
    "    all_pred_labels[i*n_samples:(i+1)*n_samples] = pred_labels\n",
    "    \n",
    "\n",
    "all_gt_labels = all_gt_labels.numpy()\n",
    "all_pred_labels = all_pred_labels.numpy()\n",
    "conf_mat = confusion_matrix(all_gt_labels, all_pred_labels)\n",
    "\n",
    "_ = plot_confusion_matrix(conf_mat, list(Config.label_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for binary classification in particular a few other metrics are useful <br>\n",
    "Many metrics can be found in the 'sklearn' library: see [scikit-learn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use the sklearn functions to calculate and print 'precision', 'recall' and 'f1-score'\n",
    "# Hint: it is very similar as for the confusion matrix\n",
    "# you can use this to check whether your understanding of the confusion matrix is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
