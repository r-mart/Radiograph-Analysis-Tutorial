{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification training pipeline using plain pytorch and a custom model\n",
    "- as classification of all 4 classes turns out to be rather difficult, we will focus on classifying negative or positive for pneumonia only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(f\"Install in: {sys.executable}\")\n",
    "# !{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To debug external functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:32.308250Z",
     "iopub.status.busy": "2021-05-21T11:21:32.307893Z",
     "iopub.status.idle": "2021-05-21T11:21:33.631675Z",
     "shell.execute_reply": "2021-05-21T11:21:33.630819Z",
     "shell.execute_reply.started": "2021-05-21T11:21:32.308211Z"
    }
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm # progress bar\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Albumenatations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "\n",
    "# importing from local package\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from src.data.datasets import ClassificationDataset\n",
    "from src.models.classification import ClassificationBaseline, ClassificationCustom\n",
    "from src.train.ClassificationTrainer import ClassificationTrainer\n",
    "from src.visualization.images import show_img\n",
    "from src.visualization.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:33.692018Z",
     "iopub.status.busy": "2021-05-21T11:21:33.691583Z",
     "iopub.status.idle": "2021-05-21T11:21:33.702230Z",
     "shell.execute_reply": "2021-05-21T11:21:33.701424Z",
     "shell.execute_reply.started": "2021-05-21T11:21:33.691982Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\" seed random number generators to make runs deterministic \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    \n",
    "class Config:\n",
    "    \"\"\" Configuration for the training \"\"\"\n",
    "    \n",
    "    time_stamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    exp_name = f\"classification_{time_stamp}\" \n",
    "    log_path = Path(\"./logs\") / exp_name    \n",
    "    fold_num: int = 0            \n",
    "    seed: int = 2021\n",
    "    num_classes: int = 2 \n",
    "    img_size: int = (768, 768) # (768, 896) # input image size    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # computing device    \n",
    "    num_workers: int = 8 # number of processors used to prepare the batches\n",
    "    batch_size: int = 16\n",
    "    n_epochs: int = 100\n",
    "    lr: float = 5e-4\n",
    "    use_scheduler = False\n",
    "    label_dict = {\n",
    "        0 : \"negative\",\n",
    "        1 : \"positive\"\n",
    "    }\n",
    "#     label_dict = {\n",
    "#         0 : \"negative\", \n",
    "#         1 : \"typical\", \n",
    "#         2 : \"indeterminate\", \n",
    "#         3 : \"atypical\"\n",
    "#     }     \n",
    "\n",
    "seed_everything(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_batch(images, gt_labels, image_ids, pred_labels=None):\n",
    "    \"\"\" plots image batch returned from dataloader and optionally predictions\n",
    "    \n",
    "    Expects data to be detached from gradients and moved to CPU\n",
    "    \"\"\"\n",
    "    \n",
    "    # for visibility, plot only a few images for large batches\n",
    "    n_plot_max = 8\n",
    "    if len(images) > n_plot_max:\n",
    "        n_plot = n_plot_max        \n",
    "        sample_idx = torch.randperm(len(images))[:n_plot]        \n",
    "        images = images[sample_idx]        \n",
    "        gt_labels = gt_labels[sample_idx]                \n",
    "        image_ids = [image_ids[i.item()] for i in sample_idx]\n",
    "        if pred_labels is not None:\n",
    "            pred_labels = pred_labels[sample_idx]\n",
    "    else:\n",
    "        n_plot = len(images)\n",
    "    \n",
    "    n_cols=2\n",
    "    n_rows=n_plot // 2    \n",
    "    \n",
    "    figsize= (n_cols * 7, n_rows * 7)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 14),  nrows=n_rows, ncols=n_cols)\n",
    "    for n in range (n_plot):    \n",
    "        img_id = image_ids[n]\n",
    "        gt_label = gt_labels[n].item()\n",
    "        img = images[n].numpy()\n",
    "        img = np.squeeze(img)\n",
    "\n",
    "        row = n // n_cols\n",
    "        col = n % n_cols \n",
    "        ax[row][col].imshow(img, cmap='gray')   \n",
    "        ax[row][col].axis('off')    \n",
    "        \n",
    "        if pred_labels is None:\n",
    "            title = f\"{image_id}: {Config.label_dict[gt_label]}\"\n",
    "        else:\n",
    "            pred_label = pred_labels[n].item()\n",
    "            title = f\"{image_id}: GT {Config.label_dict[gt_label]}, Pred {Config.label_dict[pred_label]}\"\n",
    "        \n",
    "        ax[row][col].set_title(title)    \n",
    "\n",
    "    plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data/siim-covid19-detection-subset')\n",
    "train_path = data_path / \"train\"\n",
    "\n",
    "# annotation data frame\n",
    "ann_df = pd.read_csv(data_path / \"train_annotations.csv\", converters={\n",
    "    \"boxes\": literal_eval, \n",
    "    \"labels\": literal_eval,\n",
    "    \"pixel_spacing\": literal_eval\n",
    "   })  \n",
    "\n",
    "ann_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:33.733067Z",
     "iopub.status.busy": "2021-05-21T11:21:33.732798Z",
     "iopub.status.idle": "2021-05-21T11:21:33.740040Z",
     "shell.execute_reply": "2021-05-21T11:21:33.738984Z",
     "shell.execute_reply.started": "2021-05-21T11:21:33.733038Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalization transforms\n",
    "norm_transform_list = [\n",
    "    A.Resize(height=Config.img_size[0], width=Config.img_size[1], p=1.0),\n",
    "    A.Normalize(mean=(0,), std=(1,), p=1.0),\n",
    "    ToTensorV2(p=1.0)    \n",
    "]\n",
    "\n",
    "aug_transform_list = [\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2,  \n",
    "                               contrast_limit=0.2, p=0.5)    \n",
    "]\n",
    "\n",
    "train_transforms = A.Compose(aug_transform_list + norm_transform_list)\n",
    "val_transforms = A.Compose(norm_transform_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:33.758802Z",
     "iopub.status.busy": "2021-05-21T11:21:33.758432Z",
     "iopub.status.idle": "2021-05-21T11:21:33.773130Z",
     "shell.execute_reply": "2021-05-21T11:21:33.772324Z",
     "shell.execute_reply.started": "2021-05-21T11:21:33.758766Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = ann_df[ann_df['fold'] != Config.fold_num]\n",
    "val_df = ann_df[ann_df['fold'] == Config.fold_num]\n",
    "\n",
    "train_ds = ClassificationDataset(train_df, train_path, train_transforms)\n",
    "val_ds = ClassificationDataset(val_df, train_path, val_transforms)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size = Config.batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = Config.num_workers\n",
    "    )\n",
    "val_dl = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size = Config.batch_size,\n",
    "        shuffle = False,\n",
    "        num_workers = Config.num_workers        \n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:33.774773Z",
     "iopub.status.busy": "2021-05-21T11:21:33.774430Z",
     "iopub.status.idle": "2021-05-21T11:21:33.948894Z",
     "shell.execute_reply": "2021-05-21T11:21:33.948049Z",
     "shell.execute_reply.started": "2021-05-21T11:21:33.774739Z"
    }
   },
   "outputs": [],
   "source": [
    "image, label, image_id = train_ds[2]\n",
    "\n",
    "img_np = image.numpy()\n",
    "img_np = np.squeeze(img_np)\n",
    "gt_label = label.item()\n",
    "    \n",
    "_ = show_img(img_np, figsize=(12, 12), title=f\"{image_id}: {Config.label_dict[gt_label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:33.959547Z",
     "iopub.status.busy": "2021-05-21T11:21:33.958937Z",
     "iopub.status.idle": "2021-05-21T11:21:38.481005Z",
     "shell.execute_reply": "2021-05-21T11:21:38.480021Z",
     "shell.execute_reply.started": "2021-05-21T11:21:33.959507Z"
    }
   },
   "outputs": [],
   "source": [
    "images, labels, image_ids = next(train_it)\n",
    "\n",
    "plot_image_batch(images, labels, image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:38.592357Z",
     "iopub.status.busy": "2021-05-21T11:21:38.592040Z",
     "iopub.status.idle": "2021-05-21T11:21:39.369772Z",
     "shell.execute_reply": "2021-05-21T11:21:39.368876Z",
     "shell.execute_reply.started": "2021-05-21T11:21:38.592319Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(cfg, checkpoint_path=None):\n",
    "    model = ClassificationBaseline(cfg)    \n",
    "    #model = ClassificationCustom(cfg)    \n",
    "    \n",
    "    # Load the trained weights\n",
    "    if checkpoint_path is not None:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        del checkpoint\n",
    "        gc.collect()\n",
    "        \n",
    "    return model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(Config)\n",
    "model.to(Config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:38.592357Z",
     "iopub.status.busy": "2021-05-21T11:21:38.592040Z",
     "iopub.status.idle": "2021-05-21T11:21:39.369772Z",
     "shell.execute_reply": "2021-05-21T11:21:39.368876Z",
     "shell.execute_reply.started": "2021-05-21T11:21:38.592319Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = ClassificationTrainer(model, Config)\n",
    "trainer.fit(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:40.190243Z",
     "iopub.status.busy": "2021-05-21T11:21:40.189964Z",
     "iopub.status.idle": "2021-05-21T11:21:41.276719Z",
     "shell.execute_reply": "2021-05-21T11:21:41.275880Z",
     "shell.execute_reply.started": "2021-05-21T11:21:40.190212Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = Config.log_path / 'last-checkpoint.pt'\n",
    "#model_path = Path(\"../logs/torchvision\") / \"faster_rcnn_2021-07-03_15-21-57\" / 'best-checkpoint-038epoch.pt'\n",
    "\n",
    "model = get_model(Config, checkpoint_path=model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_it = iter(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T11:21:39.417113Z",
     "iopub.status.busy": "2021-05-21T11:21:39.416817Z",
     "iopub.status.idle": "2021-05-21T11:21:40.185922Z",
     "shell.execute_reply": "2021-05-21T11:21:40.184909Z",
     "shell.execute_reply.started": "2021-05-21T11:21:39.417088Z"
    }
   },
   "outputs": [],
   "source": [
    "images, gt_labels, image_ids = next(val_it)\n",
    "images = images.to(Config.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(images)\n",
    "    \n",
    "images = images.cpu()\n",
    "_, preds = torch.max(logits, 1)\n",
    "\n",
    "pred_labels = preds.cpu()\n",
    "\n",
    "plot_image_batch(images, gt_labels, image_ids, pred_labels=pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gt_labels = torch.zeros(len(val_ds), dtype=torch.long, device='cpu')\n",
    "all_pred_labels = torch.zeros(len(val_ds), dtype=torch.long, device='cpu')\n",
    "\n",
    "for i, (images, gt_labels, image_ids) in enumerate(val_dl):\n",
    "    n_samples = len(image_ids)\n",
    "    \n",
    "    images = images.to(Config.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(images)\n",
    "    \n",
    "    _, preds = torch.max(logits, 1)\n",
    "\n",
    "    pred_labels = preds.cpu()\n",
    "    \n",
    "    all_gt_labels[i*n_samples:(i+1)*n_samples] = gt_labels\n",
    "    all_pred_labels[i*n_samples:(i+1)*n_samples] = pred_labels\n",
    "    \n",
    "\n",
    "all_gt_labels = all_gt_labels.numpy()\n",
    "all_pred_labels = all_pred_labels.numpy()\n",
    "conf_mat = confusion_matrix(all_gt_labels, all_pred_labels)\n",
    "\n",
    "_ = plot_confusion_matrix(conf_mat, list(Config.label_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for binary classification in particular a few other metrics are useful\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(all_gt_labels, all_pred_labels) * 100\n",
    "recall = recall_score(all_gt_labels, all_pred_labels) * 100\n",
    "f1 = f1_score(all_gt_labels, all_pred_labels) * 100\n",
    "\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1 Score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
